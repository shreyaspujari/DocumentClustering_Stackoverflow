{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7afdaf4-5b5a-447f-b07e-ef8ef0964b6a",
   "metadata": {},
   "source": [
    "### Sentence Transfomer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5048b9c8-de09-41fd-91c6-85cc9165f9ca",
   "metadata": {},
   "source": [
    "In this section of the project I will be using a sentence transformer in order to embedd the texts and predict the answer to the quesitons and make it easier for searching questions through large amount of data.\n",
    "\n",
    "The model will display the questions and the answers and tags associated with the questions and give out the reults.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d8f3cbb-9b38-404d-af61-ad78837fd1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95111a77-3a16-4502-8b5b-b2da7582e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the dataset and also embedd the sentences for easier search\n",
    "final_data = pd.read_csv(\"../data/final_dataset.csv\")\n",
    "\n",
    "# Preprocess and clean the questions\n",
    "def clean_text(text):\n",
    "    \"\"\"Remove HTML tags and unnecessary whitespace from the text.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = re.sub(r'<[^>]*>', '', text)  # Remove HTML tags\n",
    "    return text.strip().lower()\n",
    "\n",
    "final_data['CleanedQuestionText'] = final_data['QuestionText'].apply(clean_text)\n",
    "\n",
    "# Initialize Sentence Transformer model\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Compute sentence embeddings for all questions\n",
    "sentence_embeddings = sbert_model.encode(final_data['CleanedQuestionText'].tolist(), convert_to_tensor=True)\n",
    "\n",
    "# Save the embeddings and data for later use\n",
    "with open('../models/sbert_model.pkl', 'wb') as f:\n",
    "    pickle.dump(sbert_model, f)\n",
    "\n",
    "with open('../models/sentence_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(sentence_embeddings, f)\n",
    "\n",
    "final_data.to_csv('../data/processed_final_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ef74f-16af-46b9-94f2-c6d001e7b946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
